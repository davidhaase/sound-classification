{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Detection in MP3s using Librosa and Keras\n",
    "* Noah Sragow\n",
    "* David Haase\n",
    "\n",
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2531 files already found in /Volumes/LaCie Rose Gold 2TB/Datasets/Audio/20_Seconds/Train_20/\n",
      "Not rebuilding segments. Pass rebuild=True to force rebuild\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import librosa\n",
    "\n",
    "from audioutils import AudioSplitter, greek, arabic, turkish, persian, russian\n",
    "\n",
    "source_languages = [arabic, greek, persian, russian, turkish]\n",
    "ASML = AudioSplitter(source_languages)\n",
    "\n",
    "target_dir = '/Volumes/LaCie Rose Gold 2TB/Datasets/Audio/'\n",
    "seconds = 20\n",
    "train_dir, test_dir = ASML.split(write_dir=target_dir, duration_s=seconds, test_split=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "* Audio files split into 10-second extracts\n",
    "* 5,256 extracts created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_linear_features(file_path):\n",
    "    num_features = 40\n",
    "    res_type = 'kaiser_fast'\n",
    "\n",
    "    # handle exception to check if there isn't a file which is corrupted\n",
    "    try:\n",
    "      # here kaiser_fast is a technique used for faster extraction\n",
    "        X, sample_rate = librosa.load(file_path, res_type=res_type)\n",
    "      # we extract mfcc feature from data\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=num_features).T,axis=0)\n",
    "    except Exception as e:\n",
    "        print(e, \"Error encountered while parsing file: \", file_path)\n",
    "        return None\n",
    "\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dir = '/Volumes/LaCie Rose Gold 2TB/Datasets/Features/'\n",
    "kwargs = {'train_dir':train_dir, 'test_dir':test_dir, 'write_dir':write_dir, 'func':extract_linear_features}\n",
    "\n",
    "ASML.extract_features(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution1D, Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "\n",
    "test_size = 0.25\n",
    "random_state= 23\n",
    "target = Audio_10.train_df['Language']\n",
    "features = Audio_10.train_df['Features']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train.tolist())\n",
    "y_train = np.array(y_train.tolist())\n",
    "\n",
    "X_test = np.array(X_test.tolist())\n",
    "y_test = np.array(y_test.tolist())\n",
    "\n",
    "lb = LabelEncoder()\n",
    "\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "num_labels = y_train.shape[1]\n",
    "filter_size = 2\n",
    "num_epochs = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(num_features,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test), shuffle=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
